trigger:
  - main

pool:
  vmImage: 'ubuntu-latest'
  name: 'Default'

variables:
  - name: AZURE_ML_WORKSPACE
    value: 'azure-ml-test'
  - name: AZURE_ML_RESOURCE_GROUP
    value: 'east-us-rg-test'
  - name: MODEL_NAME
    value: 'llama-3.2-1b'
  - name: ENDPOINT_NAME
    value: 'llama-endpoint'
  - name: MODEL_PATH
    value: '$(Build.SourcesDirectory)/models'

steps:
- script: |
    sudo apt-get update
    sudo apt-get install -y software-properties-common
    sudo add-apt-repository -y ppa:deadsnakes/ppa
    sudo apt-get update
    sudo apt-get install -y python3.11 python3.11-dev python3.11-venv
    sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1
    sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1
    python3 --version
  displayName: 'Install Python 3.11'

- script: |
    python3 -m pip install --upgrade pip
    python3 -m pip install torch transformers huggingface_hub azure-ai-ml
  displayName: 'Install dependencies'

- script: |
    mkdir -p $(MODEL_PATH)
    python3 -c "
    from huggingface_hub import snapshot_download
    from transformers import AutoTokenizer, AutoModelForCausalLM
    
    # Download model and tokenizer
    model_path = '$(MODEL_PATH)'
    model_name = 'meta-llama/Llama-3.2-1B'
    
    # Download model files
    snapshot_download(
        repo_id=model_name,
        local_dir=model_path,
        token='$(HUGGINGFACE_TOKEN)'  # This should be set as a pipeline variable
    )
    "
  displayName: 'Download model from Hugging Face'

- task: AzureCLI@2
  inputs:
    azureSubscription: 'azure-subscription'
    scriptType: 'bash'
    scriptLocation: 'inlineScript'
    inlineScript: |
      # Install Azure ML CLI extension
      az extension add -n ml -y
      
      # Set up Azure ML workspace
      az ml workspace show -n $(AZURE_ML_WORKSPACE) -g $(AZURE_ML_RESOURCE_GROUP) || \
      az ml workspace create -n $(AZURE_ML_WORKSPACE) -g $(AZURE_ML_RESOURCE_GROUP)

      # Register the model
      az ml model create \
        --name $(MODEL_NAME) \
        --path $(MODEL_PATH) \
        --type custom_model

- task: AzureCLI@2
  inputs:
    azureSubscription: 'azure-subscription'
    scriptType: 'bash'
    scriptLocation: 'inlineScript'
    inlineScript: |
      # Create model deployment configuration
      cat > deployment_config.yml << EOF
      name: $(MODEL_NAME)-deployment
      model: azureml:$(MODEL_NAME)@latest
      endpoint_name: $(ENDPOINT_NAME)
      instance_type: Standard_NC6s_v3
      instance_count: 1
      app_insights_enabled: true
      request_settings:
        max_concurrent_requests_per_instance: 1
        request_timeout_ms: 90000
      traffic:
        blue: 100
      EOF

      # Deploy the model
      az ml online-endpoint create -f deployment_config.yml

- task: AzureCLI@2
  inputs:
    azureSubscription: 'azure-subscription'
    scriptType: 'bash'
    scriptLocation: 'inlineScript'
    inlineScript: |
      # Get the scoring URI
      SCORING_URI=$(az ml online-endpoint show -n $(ENDPOINT_NAME) --query "scoring_uri" -o tsv)
      echo "##vso[task.setvariable variable=SCORING_URI]$SCORING_URI"
      
      # Get the primary key
      PRIMARY_KEY=$(az ml online-endpoint get-credentials -n $(ENDPOINT_NAME) --query "primaryKey" -o tsv)
      echo "##vso[task.setvariable variable=PRIMARY_KEY]$PRIMARY_KEY" 
